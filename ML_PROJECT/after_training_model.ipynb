{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace 'path/to/your/model.h5' with the actual path to your saved model file\n",
    "model = load_model(r'C:\\Users\\shubh\\OneDrive\\Desktop\\ML_PROJECT\\group_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n",
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 50)             701600    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 50)             877050    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 50),                 20200     ['embedding[0][0]']           \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 50),           20200     ['embedding_1[0][0]',         \n",
      "                              (None, 50),                            'lstm[0][1]',                \n",
      "                              (None, 50)]                            'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, None, 50),           20200     ['lstm_1[0][0]',              \n",
      "                              (None, 50),                            'lstm_1[0][1]',              \n",
      "                              (None, 50)]                            'lstm_1[0][2]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 17541)          894591    ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2533841 (9.67 MB)\n",
      "Trainable params: 2533841 (9.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 50)             701600    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 50)             877050    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 50),                 20200     ['embedding[0][0]']           \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 50),           20200     ['embedding_1[0][0]',         \n",
      "                              (None, 50),                            'lstm[0][1]',                \n",
      "                              (None, 50)]                            'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, None, 50),           20200     ['lstm_1[0][0]',              \n",
      "                              (None, 50),                            'lstm_1[0][1]',              \n",
      "                              (None, 50)]                            'lstm_1[0][2]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 17541)          894591    ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2533841 (9.67 MB)\n",
      "Trainable params: 2533841 (9.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "\n",
    "\n",
    "lines=pd.read_csv(r\"C:\\Users\\shubh\\OneDrive\\Desktop\\ML_PROJECT\\Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "\n",
    "lines['source'].value_counts()\n",
    "\n",
    "\n",
    "lines=lines[lines['source']=='ted']\n",
    "\n",
    "\n",
    "lines.head(20)\n",
    "\n",
    "pd.isnull(lines).sum()\n",
    "\n",
    "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
    "\n",
    "lines.drop_duplicates(inplace=True)\n",
    "\n",
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n",
    "\n",
    "\n",
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)\n",
    "\n",
    "\n",
    "len(all_eng_words)\n",
    "\n",
    "len(all_hindi_words)\n",
    "\n",
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "\n",
    "lines.head()\n",
    "\n",
    "\n",
    "lines[lines['length_eng_sentence']>30].shape\n",
    "\n",
    "\n",
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]\n",
    "\n",
    "\n",
    "lines.shape\n",
    "\n",
    "\n",
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))\n",
    "\n",
    "\n",
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens\n",
    "\n",
    "\n",
    "num_decoder_tokens += 1 #for zero padding\n",
    "\n",
    "\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "\n",
    "lines = shuffle(lines)\n",
    "lines.head(10)\n",
    "\n",
    "\n",
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n",
    "\n",
    "\n",
    "def generate_batch(X=X_train, y=y_train, batch_size=128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j + batch_size], y[j:j + batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word]  # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t < max_length_tar:\n",
    "                        decoder_input_data[i, t] = target_token_index[word]  # decoder input seq\n",
    "                    if 0 < t < max_length_tar:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "\n",
    "\n",
    "#Encoder-Decoder Architecture\n",
    "\n",
    "\n",
    "latent_dim=50\n",
    "\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as the initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# First LSTM layer in the decoder\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "# Second LSTM layer in the decoder\n",
    "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm2(decoder_outputs, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer for generating the final output probabilities\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_sequence(input_sequence, max_length_src, input_token_index):\n",
    "    input_seq = np.zeros((1, max_length_src), dtype='float32')\n",
    "    for t, word in enumerate(input_sequence.split()):\n",
    "        input_seq[0, t] = input_token_index.get(word, 0)  # Use 0 for unknown tokens\n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index):\n",
    "    target_seq = np.zeros((1, max_length_tar), dtype='float32')\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    t = 0\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens = model.predict([input_sequence, target_seq])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index.get(int(sampled_token_index), 'UNK')\n",
    "\n",
    "        if sampled_char == '_END' or t >= max_length_tar - 1:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            target_seq[0, t + 1] = sampled_token_index\n",
    "            t += 1\n",
    "\n",
    "    predicted_sentence = ' '.join([reverse_target_char_index.get(int(token), 'UNK') for token in target_seq[0] if int(token) != 0])\n",
    "    return predicted_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Input Sentence: any vehicular outing with that woman from the time i was a young child\n",
      "Predicted Output: START_ असंख्य वीरान किशोर बेचे बेचे धारावाहिक धारावाहिक धारावाहिक जाएगी जाएगी अंगूर अंगूर अंगूर अधूरी अधूरी खु़द खु़द खु़द बच्चा\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"any vehicular outing with that woman from the time i was a young child\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input Sentence: and theyre different\n",
      "Predicted Output: START_ चराने रहेंगी बढ्ने बढ्ने आबादीसिर्फ आबादीसिर्फ हल्के हल्के भावताव भावताव जीनोम जीनोम जीनोम जीनोम pollen ज़रीए ज़रीए देखोगे ज़रीए\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"and theyre different\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Input Sentence: here was some lawyer or money manager\n",
      "Predicted Output: START_ कोगनिटिव इमेजिंग arthur इमेजिंग सातवींकक्षा सातवींकक्षा टुकड़ी मूर्ति मूर्ति मूर्ति खारिज खारिज जिनहे मूर्ति मूर्ति धर्मं धर्मं धर्मं लद्दाख\n"
     ]
    }
   ],
   "source": [
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"here was some lawyer or money manager\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input Sentence: any vehicular outing with that woman from the time i was a young child\n",
      "Predicted Output: START_ असंख्य वीरान किशोर बेचे बेचे धारावाहिक धारावाहिक धारावाहिक जाएगी जाएगी अंगूर अंगूर अंगूर अधूरी अधूरी खु़द खु़द खु़द बच्चा\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"any vehicular outing with that woman from the time i was a young child\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Input Sentence: to turn on the lights or to bring him a glass of water\n",
      "Predicted Output: START_ निश्चितता निजआत्म मुस्कुराना राष्ट्रों परिजनों परिजनों बढाओ।” सकूं सौरचूल्हा सकूं सौरचूल्हा ढून्ढ ढून्ढ संभालेंगे संभालेंगे पूछूँगा पूछूँगा पूछूँगा पूछूँगा\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"to turn on the lights or to bring him a glass of water\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input Sentence: Three: this is a good road in - right near where our factory is located.,\n",
      "Predicted Output: START_ mum सरोकार गठ्ठा महीलाओं महीलाओं तादाद सस्ता हटाना बहिन दोस्ती लिखी दोस्ती दोस्ती गढी। गढी। पाशचात्य चींटीं स्वेच्छासेवा स्वेच्छासेवा\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example input sentence\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"Three: this is a good road in - right near where our factory is located.,\"\n",
    "\n",
    "# Preprocess input sequence\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "# Print the predicted output\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
